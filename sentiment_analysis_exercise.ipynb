{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "zip_file = tf.keras.utils.get_file('sentiment%20labelled%20sentences.zip', \n",
    "                                 'https://github.com/stefanfausser/Business_School_HNU/raw/master/sentiment%20labelled%20sentences.zip',\n",
    "                                 extract=True)\n",
    "path = os.path.dirname(zip_file) + \"/sentiment labelled sentences/\"\n",
    "all_files = sorted(glob.glob(os.path.join(path, '*_labelled.txt')))\n",
    "df = pd.concat((pd.read_csv(f, sep='\\t', names=['Phrase','Sentiment']) for f in all_files), ignore_index=True)\n",
    "print(\"Data Points:\", len(df), \"\\n\")\n",
    "print(\"Excerpt data set:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "Sentiment_count = df.groupby('Sentiment').count()\n",
    "plt.bar(['0 (negative)', '1 (positive)'], Sentiment_count['Phrase'])\n",
    "plt.title(\"Data points by (sentiment) label\")\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Phrases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(777)\n",
    "\n",
    "# 80% training, 20% test\n",
    "train_size = int(df.shape[0] * .8)\n",
    "s = random.sample(range(df.shape[0]), df.shape[0])\n",
    "df_train = df.iloc[s[:train_size]]\n",
    "df_test = df.iloc[s[train_size:]]\n",
    "print(\"Training data points: \", len(df_train))\n",
    "print(\"Testing data points: \", len(df_test))\n",
    "# print([len(df_train), len(df_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize phrases, up to 1000 words in corpus\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 1000)\n",
    "tokenizer.fit_on_texts(df_train['Phrase'])\n",
    "print(\"Excerpt corpus:\")\n",
    "print(tokenizer.index_word[1], tokenizer.index_word[100], tokenizer.index_word[300], tokenizer.index_word[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = tf.convert_to_tensor(tokenizer.texts_to_matrix(df_train['Phrase'], mode = \"binary\"), tf.float32)\n",
    "matrix_test = tf.convert_to_tensor(tokenizer.texts_to_matrix(df_test['Phrase'], mode = \"binary\"), tf.float32)\n",
    "y_train = tf.convert_to_tensor(df_train['Sentiment'].to_numpy().reshape((-1,1)), tf.float32)\n",
    "y_test = tf.convert_to_tensor(df_test['Sentiment'].to_numpy().reshape((-1,1)), tf.float32)\n",
    "\n",
    "print(\"Dimension of training matrix (data points x features):\")\n",
    "print(matrix_train.shape, \"\\n\")\n",
    "print(\"First sentence:\")\n",
    "print(df_train['Phrase'][0], \"\\n\")\n",
    "print(\"Number of found words, first sentence:\")\n",
    "print(sum(matrix_train[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model weights\n",
    "rni = tf.random_normal_initializer(mean = 0.0, stddev = 0.05, seed = 777)\n",
    "W = tf.Variable(rni(shape = (matrix_train.shape[1], 1)))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "#@tf.function\n",
    "def model_logits(X):\n",
    "    return tf.linalg.matmul(X, W) + b\n",
    "\n",
    "#@tf.function\n",
    "def model(X):\n",
    "    return 1.0 / (1.0 + tf.exp(-model_logits(X)))\n",
    "\n",
    "# (stochastic) gradient descent\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=3)\n",
    "\n",
    "alpha = 0\n",
    "loss_fn = lambda: - tf.math.reduce_mean(\n",
    "    ys * tf.math.log(model(xs))\n",
    "    + (1.0 - ys) * tf.math.log(1.0 - model(xs))) + alpha * tf.math.reduce_mean(tf.math.abs(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_binary_confusion_matrix(x, y_true, threshold=0.5):\n",
    "    y_pred_raw = model(x)\n",
    "    def update_and_return_value(m, y_true, y_pred_raw):\n",
    "        m.update_state(y_true, y_pred_raw)\n",
    "        return m.result().numpy()        \n",
    "    tp = update_and_return_value(tf.keras.metrics.TruePositives(thresholds = threshold), y_true, y_pred_raw)\n",
    "    fp = update_and_return_value(tf.keras.metrics.FalsePositives(thresholds = threshold), y_true, y_pred_raw)\n",
    "    fn = update_and_return_value(tf.keras.metrics.FalseNegatives(thresholds = threshold), y_true, y_pred_raw)\n",
    "    tn = update_and_return_value(tf.keras.metrics.TrueNegatives(thresholds = threshold), y_true, y_pred_raw)\n",
    "    return tf.convert_to_tensor([[tp, fp],[fn, tn]])\n",
    "\n",
    "def calculate_metrics_from_binary_confusion_matrix(C):\n",
    "    [[tp, fp], [fn, tn]] = C.numpy()    \n",
    "    accuracy = round((tp + tn) / (tp + fp + tn + fn) * 100, 2)\n",
    "    sensitivity_recall = round(tp / (tp + fn) * 100, 2)\n",
    "    precision = round(tp / (tp + fp) * 100, 2)\n",
    "    specificity = round(tn / (tn + fp) * 100, 2)\n",
    "    return {'accuracy': accuracy,\n",
    "            'sensitivity_recall': sensitivity_recall,\n",
    "            'precision': precision,\n",
    "            'specificity': specificity}\n",
    "\n",
    "print(\"Model performance with randomly initialized weights (has not learned anything!):\\n\")\n",
    "print(\"Confusion matrix [[tp, fp], [fn, tn]]:\")\n",
    "C = calculate_binary_confusion_matrix(matrix_test, y_test)\n",
    "print(C.numpy(), \"\\n\")\n",
    "print(\"Metrics:\")\n",
    "print(calculate_metrics_from_binary_confusion_matrix(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "iterations = 300\n",
    "# batch_size = int(matrix_train.shape[0] / 2) # 2 batches\n",
    "batch_size = matrix_train.shape[0] # 1 batch\n",
    "losses = []\n",
    "for _ in range(iterations): \n",
    "    for i in range(0, matrix_train.shape[0], batch_size): \n",
    "        xs = matrix_train[i:i+batch_size, :]\n",
    "        ys = y_train[i:i+batch_size]\n",
    "        opt.minimize(loss_fn, var_list=[W,b])\n",
    "        losses.append(loss_fn().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zero weights?\n",
    "from matplotlib import pyplot as plt \n",
    "plt.hist(W.numpy(), bins = 100) \n",
    "plt.title(\"Weights histogram\") \n",
    "plt.xlabel('Weight value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stable updates?\n",
    "from matplotlib import pyplot as plt \n",
    "plt.plot(losses) \n",
    "plt.title(\"Loss function\")\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model performance:\\n\")\n",
    "print(\"Confusion matrix [[tp, fp], [fn, tn]]:\")\n",
    "C = calculate_binary_confusion_matrix(matrix_test, y_test, threshold = 0.5)\n",
    "print(C.numpy(), \"\\n\")\n",
    "print(\"Metrics:\")\n",
    "print(calculate_metrics_from_binary_confusion_matrix(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ['this is a great day!', 'this is not a great day', 'this is so not my day!!', 'this is my day', 'is this my day?']\n",
    "matrix = tf.convert_to_tensor(tokenizer.texts_to_matrix(phrases, mode = \"binary\"), tf.float32)\n",
    "print(\"Applying the model to further phrases:\\n\")\n",
    "print(model(matrix))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
